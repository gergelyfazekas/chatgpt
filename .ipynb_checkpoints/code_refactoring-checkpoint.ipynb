{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae8c1a6",
   "metadata": {},
   "source": [
    "## Code refactoring with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0275ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import openai\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6eeb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = config.my_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca358fd",
   "metadata": {},
   "source": [
    "### Create ChatGPT class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25062a8",
   "metadata": {},
   "source": [
    "#### We have to use suitable prompts and memory structure to achieve code refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19a4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGPT:\n",
    "    def __init__(self, api_key):\n",
    "        self.engine = \"text-davinci-003\"\n",
    "        self.openai = openai\n",
    "        self.openai.api_key = api_key\n",
    "        self.memory = \"\"\n",
    "        self.reset_memory()\n",
    "        \n",
    "        # Open the dataframe containing the prespecified prompts\n",
    "        with open(\"prompts_df.pickle\", \"rb\") as f: \n",
    "            self.prompts_df = pickle.load(f)\n",
    "        \n",
    "    def create_conversation(self, forget=True, remind_me=False, init_prompt=None):\n",
    "        \"\"\"Creates (forget=True) or continues (forget=False) a conversation interactable through prompts.\n",
    "        args:\n",
    "        forget: bool, if True: starts a new conversation, else: continues the conversation in memory\n",
    "        remind_me: bool (has an effect only if forget is False), if True: prints conversation in memory, else: nothing\n",
    "        init_prompt: str, initial prompt can be specified here instead of waiting for the input() function\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if forget:\n",
    "            self.reset_memory()\n",
    "        else:\n",
    "            if remind_me:\n",
    "                print(self.memory)\n",
    "                \n",
    "        if init_prompt:\n",
    "            user_input = init_prompt\n",
    "        else:\n",
    "            user_input = input(\"... \")\n",
    "            \n",
    "        # Want to quit?\n",
    "        if user_input.upper() in ['Q', 'QUIT', 'DONE', 'FINISHED', 'BYE', 'EXIT']:\n",
    "            return 0\n",
    "        \n",
    "        # Not quitting -- continue conversation\n",
    "        else:\n",
    "            self.remember(last_text = user_input, user=True)\n",
    "            r = self.respond(prompt=self.memory)\n",
    "            print(r)\n",
    "            self.remember(last_text = r, user=False)\n",
    "            self.create_conversation(forget=False, remind_me=False, init_prompt=None)\n",
    "            \n",
    "    def remember(self, last_text, user):\n",
    "        \"\"\"Appends the last_text to the memory in a suitable format.\"\"\"\n",
    "        if user:\n",
    "            t = str(\" I said: \" + last_text)\n",
    "        else:\n",
    "            t = str(\" You said: \" + last_text)\n",
    "        self.memory += t\n",
    "        \n",
    "    def reset_memory(self):\n",
    "        \"\"\"Resets the memory to a suitable form (not empty) to be able to start a new conversation or question.\"\"\"\n",
    "        self.memory = str(\"I would like you to finish or continue our conversation as a tutor, \" +\n",
    "                          \"teacher or professor would in that situation, \" +\n",
    "                          \"by giving the precise answer \" +\n",
    "                          \"if the end of the conversation can be answered in a simple or precise way. \" +\n",
    "                          \"Let's pretend that so far we discussed the following: \")\n",
    "        \n",
    "    def respond(self, prompt, max_tokens=100, n=1, stop=None, temperature=0.2):\n",
    "        \"\"\"Creates a response based on prompt.\"\"\"\n",
    "        completion = self.openai.Completion.create(engine=self.engine,\n",
    "                                              prompt=prompt,\n",
    "                                              max_tokens=max_tokens,\n",
    "                                              n=n,\n",
    "                                              stop=None,\n",
    "                                              temperature=temperature)\n",
    "        \n",
    "        response = completion.choices[0].text\n",
    "        return response\n",
    "    \n",
    "    def suggest(self, f, focus=\"speed\", code_bool=True, **kwargs):\n",
    "        \"\"\"Reviews the given function and returns suggestions in english or refactored code based on the arguments.\n",
    "        \n",
    "        args:\n",
    "        \n",
    "        f: function to review\n",
    "        \n",
    "        focus: one of ['speed', 'style', 'explain']\n",
    "            'speed': suggestion will focus on speeding up the function\n",
    "            'style': suggestion will focus on making it more pythonic/conventional/style-guide-like\n",
    "            'explain': suggestion will return an english text about what the function is doing/achieving\n",
    "            \n",
    "        code_bool: bool, \n",
    "                    if True the returned value will be the python function refactored per the suggestion,\n",
    "                    else: an english explanation is returned\n",
    "                    \n",
    "        kwargs:\n",
    "        keyword arguments passed to self.respond (e.g. max_tokens to specify answer length)\n",
    "        \"\"\"\n",
    "        assert focus in ['speed', 'style', 'explain']\n",
    "        assert isinstance(code_bool, bool)\n",
    "        \n",
    "        s = self.prompts_df.loc[\n",
    "            (self.prompts_df['mode'] == focus) & (self.prompts_df['code_bool'] == code_bool),\n",
    "            'prompt'].to_list()[0]\n",
    "            \n",
    "            \n",
    "        c = inspect.getsource(f)\n",
    "        prompt = s + c\n",
    "        self.remember(prompt, user=True)\n",
    "        response = self.respond(prompt=prompt, **kwargs)\n",
    "        self.remember(response, user=False)\n",
    "        return response\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77478691",
   "metadata": {},
   "source": [
    "### Create an inefficient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43aca900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a):\n",
    "    l = [1,2,3,4,5]\n",
    "    \n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i] + a\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db996e66",
   "metadata": {},
   "source": [
    "### Initialize an instance of ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc27af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ChatGPT(my_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025c64b",
   "metadata": {},
   "source": [
    "### Call refactoring on function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73668a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat GPT's answer: \n",
      "------------------------ \n",
      "\n",
      "def my_func(a):\n",
      "    l = [1,2,3,4,5]\n",
      "    \n",
      "    l = [x + a for x in l]\n",
      "    \n",
      "    return l\n"
     ]
    }
   ],
   "source": [
    "print(\"Chat GPT's answer: \")\n",
    "print(\"------------------------ \")\n",
    "\n",
    "response = c.suggest(my_func, focus='speed', code_bool=True, **{'max_tokens':500})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6fa46",
   "metadata": {},
   "source": [
    "### Continue discussion if one step was not sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe8b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_question = \"Could you show me another way using numpy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e74fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You could use numpy to increase the speed of your code by using the numpy.add function. For example, you could rewrite your code as follows:\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def my_func(a):\n",
      "    l = np.array([1,2,3,4,5])\n",
      "    \n",
      "    l = np.add(l, a)\n",
      "    \n",
      "    return l\n",
      "... bye\n"
     ]
    }
   ],
   "source": [
    "discuss = c.create_conversation(forget=False, remind_me=False, init_prompt=next_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
